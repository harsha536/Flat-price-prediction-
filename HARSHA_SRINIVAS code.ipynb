{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "657c0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e76411da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files\n",
    "training_data_path = 'training_data.csv'\n",
    "training_targets_path = 'training_data_targets.csv'\n",
    "test_data_path = 'test_data.csv'\n",
    "\n",
    "# Reading the CSV files\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "training_targets = pd.read_csv(training_targets_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab2a1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing numerical columns\n",
    "numerical_cols = ['SQUARE_FT', 'LONGITUDE', 'LATITUDE']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "training_data_normalized = training_data.copy()\n",
    "test_data_normalized = test_data.copy()\n",
    "\n",
    "training_data_normalized[numerical_cols] = scaler.fit_transform(training_data[numerical_cols])\n",
    "test_data_normalized[numerical_cols] = scaler.transform(test_data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52736e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_792\\3169767683.py:8: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  city_frequency = training_data_fe['CITY'].append(test_data_fe['CITY']).value_counts()\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering and Frequency Encoding for 'ADDRESS'\n",
    "training_data_fe = training_data_normalized.copy()\n",
    "test_data_fe = test_data_normalized.copy()\n",
    "\n",
    "training_data_fe['CITY'] = training_data_fe['ADDRESS'].apply(lambda x: x.split(',')[-1].strip())\n",
    "test_data_fe['CITY'] = test_data_fe['ADDRESS'].apply(lambda x: x.split(',')[-1].strip())\n",
    "\n",
    "city_frequency = training_data_fe['CITY'].append(test_data_fe['CITY']).value_counts()\n",
    "training_data_fe['CITY'] = training_data_fe['CITY'].map(city_frequency)\n",
    "test_data_fe['CITY'] = test_data_fe['CITY'].map(city_frequency)\n",
    "\n",
    "training_data_fe.drop('ADDRESS', axis=1, inplace=True)\n",
    "test_data_fe.drop('ADDRESS', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83e59bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning the training data with the training targets\n",
    "X_aligned = training_data_fe.iloc[:-1]\n",
    "y = training_targets.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b279b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_aligned, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ac80f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and training models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results_aligned = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "    results_aligned[name] = np.sqrt(mse)  # Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29767b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear Regression', 571.533825735233)\n",
      "('Decision Tree', 914.524388967419)\n",
      "('Random Forest', 680.76504985028)\n",
      "('Gradient Boosting', 582.3312278930188)\n"
     ]
    }
   ],
   "source": [
    "for results in results_aligned.items():\n",
    "  print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e8a08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_regressor = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae12bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad67d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNDER_CONSTRUCTION</th>\n",
       "      <th>RERA</th>\n",
       "      <th>BHK_NO.</th>\n",
       "      <th>SQUARE_FT</th>\n",
       "      <th>READY_TO_MOVE</th>\n",
       "      <th>RESALE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1057.896332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nayabad,Kolkata</td>\n",
       "      <td>22.483471</td>\n",
       "      <td>88.417711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340.588282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sector 42 Seawoods,Lalitpur</td>\n",
       "      <td>28.456809</td>\n",
       "      <td>77.099182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Indirapuram,Ghaziabad</td>\n",
       "      <td>28.636760</td>\n",
       "      <td>77.363150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1800.327332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Navratna Complex,Udaipur</td>\n",
       "      <td>24.583330</td>\n",
       "      <td>73.683330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>903.024911</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Madhyamgram,Kolkata</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>88.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNDER_CONSTRUCTION  RERA  BHK_NO.    SQUARE_FT  READY_TO_MOVE  RESALE  \\\n",
       "0                   0     0        3  1057.896332              1       1   \n",
       "1                   0     0        3  1340.588282              1       1   \n",
       "2                   0     0        2   800.000000              1       1   \n",
       "3                   0     0        3  1800.327332              1       1   \n",
       "4                   1     0        2   903.024911              0       1   \n",
       "\n",
       "                       ADDRESS  LONGITUDE   LATITUDE  \n",
       "0              Nayabad,Kolkata  22.483471  88.417711  \n",
       "1  Sector 42 Seawoods,Lalitpur  28.456809  77.099182  \n",
       "2        Indirapuram,Ghaziabad  28.636760  77.363150  \n",
       "3     Navratna Complex,Udaipur  24.583330  73.683330  \n",
       "4          Madhyamgram,Kolkata  22.700000  88.450000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69dc99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "test_data_encoded = encoder.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f69b1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded Feature Names: \n",
      " ['UNDER_CONSTRUCTION_0' 'UNDER_CONSTRUCTION_1' 'RERA_0' ...\n",
      " 'LATITUDE_106.784197' 'LATITUDE_132.764401' 'LATITUDE_136.0']\n"
     ]
    }
   ],
   "source": [
    "feature_names = encoder.get_feature_names_out(test_data.columns)\n",
    "print(\"\\nOne-Hot Encoded Feature Names: \\n\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9b3c3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded Dataset:\n",
      "    UNDER_CONSTRUCTION_0  UNDER_CONSTRUCTION_1  RERA_0  RERA_1  BHK_NO._1  \\\n",
      "0                   1.0                   0.0     1.0     0.0        0.0   \n",
      "1                   1.0                   0.0     1.0     0.0        0.0   \n",
      "2                   1.0                   0.0     1.0     0.0        0.0   \n",
      "3                   1.0                   0.0     1.0     0.0        0.0   \n",
      "4                   0.0                   1.0     1.0     0.0        0.0   \n",
      "\n",
      "   BHK_NO._2  BHK_NO._3  BHK_NO._4  BHK_NO._5  BHK_NO._6  ...  \\\n",
      "0        0.0        1.0        0.0        0.0        0.0  ...   \n",
      "1        0.0        1.0        0.0        0.0        0.0  ...   \n",
      "2        1.0        0.0        0.0        0.0        0.0  ...   \n",
      "3        0.0        1.0        0.0        0.0        0.0  ...   \n",
      "4        1.0        0.0        0.0        0.0        0.0  ...   \n",
      "\n",
      "   LATITUDE_91.748271  LATITUDE_91.754959  LATITUDE_91.76667  \\\n",
      "0                 0.0                 0.0                0.0   \n",
      "1                 0.0                 0.0                0.0   \n",
      "2                 0.0                 0.0                0.0   \n",
      "3                 0.0                 0.0                0.0   \n",
      "4                 0.0                 0.0                0.0   \n",
      "\n",
      "   LATITUDE_91.797708  LATITUDE_91.802088  LATITUDE_91.805142  \\\n",
      "0                 0.0                 0.0                 0.0   \n",
      "1                 0.0                 0.0                 0.0   \n",
      "2                 0.0                 0.0                 0.0   \n",
      "3                 0.0                 0.0                 0.0   \n",
      "4                 0.0                 0.0                 0.0   \n",
      "\n",
      "   LATITUDE_102.136839  LATITUDE_106.784197  LATITUDE_132.764401  \\\n",
      "0                  0.0                  0.0                  0.0   \n",
      "1                  0.0                  0.0                  0.0   \n",
      "2                  0.0                  0.0                  0.0   \n",
      "3                  0.0                  0.0                  0.0   \n",
      "4                  0.0                  0.0                  0.0   \n",
      "\n",
      "   LATITUDE_136.0  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n",
      "\n",
      "[5 rows x 6588 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data_encoded_df = pd.DataFrame(test_data_encoded.toarray(), columns=feature_names)\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Dataset:\\n\", test_data_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d825be4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbest_lr_regressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:354\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:335\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 335\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m], reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "test_predictions = best_lr_regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "edb6dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your features X_train and target variable y_train\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_aligned, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr_regressor = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Now the model is fitted, and you can make predictions\n",
    "test_predictions = lr_regressor.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33b3b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({'predicted_label': test_predictions})\n",
    "predictions_df.to_csv('predictions.txt', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847cb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
